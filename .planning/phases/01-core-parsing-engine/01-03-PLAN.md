---
phase: 01-core-parsing-engine
plan: 03
type: execute
wave: 3
depends_on: ["01-02"]
files_modified: ["src/engine/fsm.rs", "src/engine/records.rs", "Cargo.toml"]
autonomous: true
must_haves:
  truths:
    - "Required values missing in a match cause the record to be dropped"
    - "Filldown values persist across subsequent records until cleared"
    - "Engine throughput is measured and recorded"
  artifacts:
    - path: "src/engine/records.rs"
      provides: "Record buffer and validation"
    - path: "benches/throughput.rs"
      provides: "Criterion benchmarks"
  key_links:
    - from: "src/engine/fsm.rs"
      to: "src/engine/records.rs"
      via: "pushing captured groups to buffer"
---

<objective>
Implement the data capture logic (Record, Filldown, Required) and add performance benchmarks.
</objective>

<execution_context>
@~/.opencode/get-shit-done/workflows/execute-plan.md
@~/.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-core-parsing-engine/01-CONTEXT.md
@.planning/phases/01-core-parsing-engine/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Record and Value Capture Logic</name>
  <files>src/engine/fsm.rs, src/engine/records.rs</files>
  <action>
    Implement logic to handle Record actions and data persistence.
    1. Create `src/engine/records.rs` to manage the `current_record` buffer.
    2. In the FSM loop, when a rule matches:
       - Extract named capture groups into the buffer.
       - If action is `Record`:
         - Verify all `Required` fields are non-empty.
         - If valid, clone buffer to result set.
         - Clear non-`Filldown` values from buffer.
       - If action is `Clear`: Wipe buffer.
  </action>
  <verify>
    - Unit test for `Filldown`: Verify value persists across two records.
    - Unit test for `Required`: Verify record is dropped if required field is missing.
  </verify>
  <done>
    Record management supports Filldown and Required constraints.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add Throughput Benchmarks</name>
  <files>Cargo.toml, benches/throughput.rs</files>
  <action>
    Add benchmarks to verify performance.
    1. Add `criterion` to `[dev-dependencies]` in `Cargo.toml`.
    2. Create `benches/throughput.rs`.
    3. Benchmark the `parse` function with a 100,000 line input and a standard template.
  </action>
  <verify>
    Run `cargo bench` and verify the output shows lines processed per second.
  </verify>
  <done>
    Performance is benchmarked and meets the >100k lines/sec target.
  </done>
</task>

</tasks>

<verification>
- `cargo test` passes.
- `cargo bench` runs successfully.
</verification>

<success_criteria>
The engine produces correct structured data from text input, respecting TextFSM capture rules, and meets the performance goal.
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-parsing-engine/01-03-SUMMARY.md`
</output>
